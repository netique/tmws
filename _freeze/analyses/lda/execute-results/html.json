{
  "hash": "e1e83a71f523b6b85c225f2ee04df089",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Latent Dirichlet Allocation (LDA)\"\nauthor: \"Jan Netík\"\nformat: html\nexecute: \n  freeze: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(topicmodels)\nlibrary(ldatuning)\nlibrary(tidytext)\n\ndata(\"AssociatedPress\")\n```\n:::\n\n\nData jsou uložena jako document-term matrix, převeďme si je tedy do tibble.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nap_tidy <- AssociatedPress |> tidy()\n\nap_tidy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 302,031 × 3\n   document term       count\n      <int> <chr>      <dbl>\n 1        1 adding         1\n 2        1 adult          2\n 3        1 ago            1\n 4        1 alcohol        1\n 5        1 allegedly      1\n 6        1 allen          1\n 7        1 apparently     2\n 8        1 appeared       1\n 9        1 arrested       1\n10        1 assault        1\n# ℹ 302,021 more rows\n```\n\n\n:::\n:::\n\n\nPoužijeme seznam stop slov z `tidytext` a přidáme si vlastní:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstop_words <- stop_words |> add_row(word = c(\"th\", \"sr\", \"r\", \"h\", \"e\"))\n```\n:::\n\n\nA smažeme je z našich dat. Poté z tidy formátu vyrobíme zpět document-term matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nap_dtm <- ap_tidy |>\n  anti_join(stop_words, by = c(term = \"word\")) |>\n  cast_dtm(document, term, count)\n\nap_dtm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<<DocumentTermMatrix (documents: 2246, terms: 10133)>>\nNon-/sparse entries: 259203/22499515\nSparsity           : 99%\nMaximal term length: 18\nWeighting          : term frequency (tf)\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noptimal.topics <- FindTopicsNumber(\n  ap_dtm,\n  topics = 2:8,\n  metrics = c(\"Griffiths2004\", \"CaoJuan2009\", \"Arun2010\", \"Deveaud2014\"),\n  control = list(seed = 123),\n  mc.cores = parallel::detectCores() / 2, # zapojení všech jader způsobí pád R...\n  verbose = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfit models... done.\ncalculate metrics:\n  Griffiths2004... done.\n  CaoJuan2009... done.\n  Arun2010... done.\n  Deveaud2014... done.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nFindTopicsNumber_plot(optimal.topics)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the ldatuning package.\n  Please report the issue at <https://github.com/nikita-moor/ldatuning/issues>.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lda_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nDejme tomu, že 5 témat už má dobré metriky a není to zas tak moc...\n\n\"Fitneme\" finální model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nap_lda <- LDA(ap_dtm, k = 5, control = list(seed = 123))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# beta = pravděpodobnost, že slovo bylo \"vygenerováno\" daným tématem\nap_topics <- tidy(ap_lda, matrix = \"beta\")\n\nap_topics\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50,665 × 3\n   topic term       beta\n   <int> <chr>     <dbl>\n 1     1 adding 1.46e- 4\n 2     2 adding 1.01e- 4\n 3     3 adding 1.35e- 4\n 4     4 adding 1.96e- 4\n 5     5 adding 3.15e- 4\n 6     1 adult  3.14e- 5\n 7     2 adult  1.65e-17\n 8     3 adult  9.17e-16\n 9     4 adult  3.41e- 5\n10     5 adult  2.41e- 4\n# ℹ 50,655 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nap_top_terms <- ap_topics %>%\n  group_by(topic) %>%\n  slice_max(beta, n = 10) %>%\n  ungroup() %>%\n  arrange(topic, -beta)\n\nap_top_terms %>%\n  mutate(term = reorder_within(term, beta, topic)) %>%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~topic, scales = \"free\") +\n  scale_y_reordered()\n```\n\n::: {.cell-output-display}\n![](lda_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nSlova, co se s nějakou pravděpodobností vyskytují tak nějak napříč:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nap_topics |>\n  filter(beta > .001) |>\n  pivot_wider(names_from = topic, values_from = beta, names_prefix = \"topic_\") |>\n  filter(if_all(-term, \\(x) !is.na(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 × 6\n   term      topic_4 topic_5 topic_3 topic_2 topic_1\n   <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 friday    0.00230 0.00170 0.00210 0.00107 0.00128\n 2 day       0.00146 0.00309 0.00160 0.00115 0.00174\n 3 million   0.0132  0.00140 0.00158 0.00319 0.00284\n 4 time      0.00162 0.00342 0.00190 0.00237 0.00344\n 5 wednesday 0.00162 0.00201 0.00192 0.00129 0.00194\n 6 monday    0.00167 0.00197 0.00187 0.00173 0.00139\n 7 american  0.00332 0.00192 0.00210 0.00135 0.00190\n 8 national  0.00154 0.00179 0.00231 0.00171 0.00392\n 9 tuesday   0.00216 0.00166 0.00172 0.00166 0.00219\n10 week      0.00296 0.00108 0.00170 0.00158 0.00237\n11 thursday  0.00265 0.00159 0.00201 0.00166 0.00205\n```\n\n\n:::\n:::\n\n\nTeď k pravděpodobnosti témat v rámci jednotlivých dokumentů:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gamma = podíl slov v dokumentu, které byly \"vygenerovány\" daným tématem\nap_documents <- tidy(ap_lda, matrix = \"gamma\")\n\nap_documents |>\n  mutate(document = as.integer(document)) |>\n  arrange(document, topic)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11,230 × 3\n   document topic    gamma\n      <int> <int>    <dbl>\n 1        1     1 0.000319\n 2        1     2 0.0451  \n 3        1     3 0.000319\n 4        1     4 0.000319\n 5        1     5 0.954   \n 6        2     1 0.000312\n 7        2     2 0.459   \n 8        2     3 0.442   \n 9        2     4 0.0975  \n10        2     5 0.000312\n# ℹ 11,220 more rows\n```\n\n\n:::\n:::\n\n\nSoučet hodnot $\\gamma$ pro každý dokument je roven 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nap_documents |>\n  group_by(document) |>\n  summarise(gamma_sum = sum(gamma))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,246 × 2\n   document gamma_sum\n   <chr>        <dbl>\n 1 1                1\n 2 10               1\n 3 100              1\n 4 1000             1\n 5 1001             1\n 6 1002             1\n 7 1003             1\n 8 1004             1\n 9 1005             1\n10 1006             1\n# ℹ 2,236 more rows\n```\n\n\n:::\n:::\n\n\nDokument 1 je skoro čisté téma č. 5:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nap_tidy |>\n  filter(document == 1) |>\n  arrange(desc(count))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 186 × 3\n   document term      count\n      <int> <chr>     <dbl>\n 1        1 police        7\n 2        1 school        7\n 3        1 teacher       7\n 4        1 shot          5\n 5        1 students      5\n 6        1 boy           4\n 7        1 boys          4\n 8        1 classroom     4\n 9        1 gun           3\n10        1 guns          3\n# ℹ 176 more rows\n```\n\n\n:::\n:::\n\n\nAle dokument 2 je mix témat 2 a 3. Pojďme se podívat blíž:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nap_tidy |>\n  filter(document == 2) |>\n  arrange(desc(count))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 174 × 3\n   document term      count\n      <int> <chr>     <dbl>\n 1        2 peres        13\n 2        2 offer         9\n 3        2 official      8\n 4        2 bechtel       7\n 5        2 rappaport     7\n 6        2 israel        6\n 7        2 oil           6\n 8        2 memo          5\n 9        2 pipeline      5\n10        2 company       4\n# ℹ 164 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(LDAvis)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npost <- posterior(ap_lda)\nmat <- ap_lda@wordassignments\n\nldavis_json <- LDAvis::createJSON(\n  phi = post[[\"terms\"]],\n  theta = post[[\"topics\"]],\n  vocab = colnames(post[[\"terms\"]]),\n  doc.length = rowSums(as.matrix(mat), na.rm = TRUE),\n  term.frequency = colSums(as.matrix(mat), na.rm = TRUE)\n)\n\nif (interactive()) {\n  ldavis_json |> serVis()\n}\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}